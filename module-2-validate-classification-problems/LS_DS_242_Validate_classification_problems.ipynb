{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMI2k-oBsS08"
   },
   "source": [
    "_Lambda School Data Science — Model Validation_ \n",
    "\n",
    "# Validate classification problems\n",
    "\n",
    "Objectives\n",
    "- Imbalanced Classes\n",
    "- Confusion Matrix\n",
    "- ROC AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUZCkblZYN60"
   },
   "source": [
    "Reading\n",
    "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
    "- [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rU7RuVcjWdcp"
   },
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jes2WnwV072n"
   },
   "source": [
    "We'll use [mlxtend](http://rasbt.github.io/mlxtend/) and [yellowbrick](http://www.scikit-yb.org/en/latest/) for visualizations. These libraries are already installed on Google Colab. But if you are running locally with Anaconda Python, you'll probably need to install them:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge mlxtend \n",
    "conda install -c districtdatalabs yellowbrick\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQYGb3HgEp8b"
   },
   "source": [
    "We'll reuse the `train_validation_test_split` function from yesterday's lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMTjC3vQ7ZNV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validation_test_split(\n",
    "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, \n",
    "    random_state=None, shuffle=True):\n",
    "        \n",
    "    assert train_size + val_size + test_size == 1\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_size/(train_size+val_size), \n",
    "        random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWLBlu5K5kJR"
   },
   "source": [
    "## Fun demo!\n",
    "\n",
    "The next code cell does five things:\n",
    "\n",
    "#### 1. Generate data\n",
    "\n",
    "We use scikit-learn's [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function to generate fake data for a binary classification problem, based on several parameters, including:\n",
    "- Number of samples\n",
    "- Weights, meaning \"the proportions of samples assigned to each class.\"\n",
    "- Class separation: \"Larger values spread out the clusters/classes and make the classification task easier.\"\n",
    "\n",
    "(We are generating fake data so it is easy to visualize.)\n",
    "\n",
    "#### 2. Split data\n",
    "\n",
    "We split the data three ways, into train, validation, and test sets. (For this toy example, it's not really necessary to do a three-way split. A two-way split, or even no split, would be ok. But I'm trying to demonstrate good habits, even in toy examples, to avoid confusion.)\n",
    "\n",
    "#### 3. Fit model\n",
    "\n",
    "We use scikit-learn to fit a [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the training data.\n",
    "\n",
    "We use this model parameter:\n",
    "\n",
    "> **class_weight : _dict or ‘balanced’, default: None_**\n",
    "\n",
    "> Weights associated with classes in the form `{class_label: weight}`. If not given, all classes are supposed to have weight one.\n",
    "\n",
    "> The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n_samples / (n_classes * np.bincount(y))`.\n",
    "\n",
    "\n",
    "#### 4. Evaluate model\n",
    "\n",
    "We use our Logistic Regression model, which was fit on the training data, to generate predictions for the validation data.\n",
    "\n",
    "Then we print [scikit-learn's Classification Report](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), with many metrics, and also the accuracy score. We are comparing the correct labels to the Logistic Regression's predicted labels, for the validation set. \n",
    "\n",
    "#### 5. Visualize decision function\n",
    "\n",
    "Based on these examples\n",
    "- https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/combine/plot_comparison_combine.html\n",
    "- http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/#example-1-decision-regions-in-2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcpoWCUq5xNV"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "#1. Generate data\n",
    "\n",
    "# Try re-running the cell with different values for these parameters\n",
    "n_samples = 1000\n",
    "weights = (0.50, 0.50)\n",
    "class_sep = 0.8\n",
    "\n",
    "X, y = make_classification(n_samples=n_samples, n_features=2, n_informative=2, \n",
    "                           n_redundant=0, n_repeated=0, n_classes=2, \n",
    "                           n_clusters_per_class=1, weights=weights, \n",
    "                           class_sep=class_sep, random_state=0)\n",
    "\n",
    "\n",
    "# 2. Split data\n",
    "\n",
    "# Uses our custom train_validation_test_split function\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
    "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=1)\n",
    "\n",
    "\n",
    "# 3. Fit model\n",
    "\n",
    "# Try re-running the cell with different values for this parameter\n",
    "class_weight = None\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', class_weight=class_weight)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 4. Evaluate model\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print('accuracy', accuracy_score(y_val, y_pred))\n",
    "\n",
    "\n",
    "# 5. Visualize decision regions\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_decision_regions(X_val, y_val, model, legend=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrllN3yECsEN"
   },
   "source": [
    "Try re-running the cell above with different values for these four parameters:\n",
    "- `n_samples`\n",
    "- `weights`\n",
    "- `class_sep`\n",
    "- `class_balance`\n",
    "\n",
    "For example, with a 50% / 50% class distribution:\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.50, 0.50)\n",
    "class_sep = 0.8\n",
    "class_balance = None\n",
    "```\n",
    "\n",
    "With a 95% / 5% class distribution:\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.95, 0.05)\n",
    "class_sep = 0.8\n",
    "class_balance = None\n",
    "```\n",
    "\n",
    "With the same 95% / 5% class distribution, but changing the Logistic Regression's `class_balance` parameter to `'balanced'` (instead of its default `None`)\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.95, 0.05)\n",
    "class_sep = 0.8\n",
    "class_balance = 'balanced'\n",
    "```\n",
    "\n",
    "With the same 95% / 5% class distribution, but with different values for `class_balance`:\n",
    "- `{0: 1, 1: 1}` _(equivalent to `None`)_\n",
    "- `{1: 1, 1: 2}`\n",
    "- `{1: 1, 1: 10}` _(roughly equivalent to `'balanced'` for this dataset)_\n",
    "- `{1: 1, 1: 100}`\n",
    "- `{1: 1, 1: 10000}`\n",
    "\n",
    "How do the evaluation metrics and decision region plots change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-3MS-jANssN"
   },
   "source": [
    "## What you can do about imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KwgStd-yUUr"
   },
   "source": [
    "[Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/) gives \"a rough outline of useful approaches\" : \n",
    "\n",
    "- Do nothing. Sometimes you get lucky and nothing needs to be done. You can train on the so-called natural (or stratified) distribution and sometimes it works without need for modification.\n",
    "- Balance the training set in some way:\n",
    "  - Oversample the minority class.\n",
    "  - Undersample the majority class.\n",
    "  - Synthesize new minority classes.\n",
    "- Throw away minority examples and switch to an anomaly detection framework.\n",
    "- At the algorithm level, or after it:\n",
    "  - Adjust the class weight (misclassification costs).\n",
    "  - Adjust the decision threshold.\n",
    "  - Modify an existing algorithm to be more sensitive to rare classes.\n",
    "- Construct an entirely new algorithm to perform well on imbalanced data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iO7kOZ2HN0EA"
   },
   "source": [
    "We demonstrated just one of these options: many scikit-learn classifiers have a `class_balance` parameter, which we can use to \"adjust the class weight (misclassification costs).\"\n",
    "\n",
    "The [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library can be used to \"oversample the minority class, undersample the majority class, or synthesize new minority classes.\"\n",
    "\n",
    "You can see how to \"adjust the decision threshold\" in a great blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xhh5TiW_X1_Q"
   },
   "source": [
    "## Bank Marketing — getting started\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \n",
    "\n",
    "bank-additional-full.csv with all examples (41188) and 20 inputs, **ordered by date (from May 2008 to November 2010)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n18wVnuxY-xl"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-oHbkK1X1h2"
   },
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "1INLmiipZA-y"
   },
   "outputs": [],
   "source": [
    "!unzip bank-additional.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwWCY5XrZCWk"
   },
   "outputs": [],
   "source": [
    "%cd bank-additional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zf49DcHTZPdE"
   },
   "source": [
    "### Load data, assign to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwhVgENcZEwo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bank = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "X = bank.drop(columns='y')\n",
    "y = bank['y'] == 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lq1it0dnZlX3"
   },
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-FgY4pIaEXo"
   },
   "source": [
    "We want to do \"model selection (hyperparameter optimization) and performance estimation\" so we'll choose a validation method from the diagram's green box.\n",
    "\n",
    "There is no one \"right\" choice here, but I'll choose \"3-way holdout method (train/validation/test split).\"\n",
    "  \n",
    "<img src=\"https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg\" width=\"600\">\n",
    "\n",
    "Source: https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V74i3GDcZnkm"
   },
   "source": [
    "There's no one \"right\" choice here, but I'll choose to split by time, not with a random shuffle, based on this advice by [Rachel Thomas](\n",
    "https://www.fast.ai/2017/11/13/validation-sets/):\n",
    "> If your data is a time series, choosing a random subset of the data will be both too easy (you can look at the data both before and after the dates your are trying to predict) and not representative of most business use cases (where you are using historical data to build a model for use in the future).\n",
    "\n",
    "[According to UCI](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing), this data is \"ordered by date (from May 2008 to November 2010)\" so if I don't shuffle it when splitting, then it will be split by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xnw-vfOamHH"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
    "    X, y, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12dWJxXabDxt"
   },
   "source": [
    "## Bank Marketing — live coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAPOJu3uamrU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_XjBTW5SBwZ"
   },
   "source": [
    "# ASSIGNMENT options\n",
    "\n",
    "Replicate code from the lesson or other examples. [Do it \"the hard way\" or with the \"Benjamin Franklin method.\"](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit)\n",
    "\n",
    "Work with one of these datasets\n",
    "- [Bank Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)\n",
    "- [Synthetic Financial Dataset For Fraud Detection](https://www.kaggle.com/ntnu-testimon/paysim1)\n",
    "- Any imbalanced binary classification dataset\n",
    "\n",
    "Continue improving your model. Measure validation performance with a variety of classification metrics, which could include:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- ROC AUC\n",
    "\n",
    "Try one of the other options mentioned for imbalanced classes\n",
    "- The [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library can be used to \"oversample the minority class, undersample the majority class, or synthesize new minority classes.\"\n",
    "- You can see how to \"adjust the decision threshold\" in a great blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import zipfile \n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('C:/Users/dakot/Downloads/paysim1.zip')\n",
    "df = pd.read_csv(zf.open(zipfile.ZipFile.namelist(zf)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns = ['nameOrig','nameDest'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.433972e+02</td>\n",
       "      <td>1.798619e+05</td>\n",
       "      <td>8.338831e+05</td>\n",
       "      <td>8.551137e+05</td>\n",
       "      <td>1.100702e+06</td>\n",
       "      <td>1.224996e+06</td>\n",
       "      <td>1.290820e-03</td>\n",
       "      <td>2.514687e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.423320e+02</td>\n",
       "      <td>6.038582e+05</td>\n",
       "      <td>2.888243e+06</td>\n",
       "      <td>2.924049e+06</td>\n",
       "      <td>3.399180e+06</td>\n",
       "      <td>3.674129e+06</td>\n",
       "      <td>3.590480e-02</td>\n",
       "      <td>1.585775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.560000e+02</td>\n",
       "      <td>1.338957e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.390000e+02</td>\n",
       "      <td>7.487194e+04</td>\n",
       "      <td>1.420800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.327057e+05</td>\n",
       "      <td>2.146614e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>2.087215e+05</td>\n",
       "      <td>1.073152e+05</td>\n",
       "      <td>1.442584e+05</td>\n",
       "      <td>9.430367e+05</td>\n",
       "      <td>1.111909e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.430000e+02</td>\n",
       "      <td>9.244552e+07</td>\n",
       "      <td>5.958504e+07</td>\n",
       "      <td>4.958504e+07</td>\n",
       "      <td>3.560159e+08</td>\n",
       "      <td>3.561793e+08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
       "count  6.362620e+06  6.362620e+06   6.362620e+06    6.362620e+06   \n",
       "mean   2.433972e+02  1.798619e+05   8.338831e+05    8.551137e+05   \n",
       "std    1.423320e+02  6.038582e+05   2.888243e+06    2.924049e+06   \n",
       "min    1.000000e+00  0.000000e+00   0.000000e+00    0.000000e+00   \n",
       "25%    1.560000e+02  1.338957e+04   0.000000e+00    0.000000e+00   \n",
       "50%    2.390000e+02  7.487194e+04   1.420800e+04    0.000000e+00   \n",
       "75%    3.350000e+02  2.087215e+05   1.073152e+05    1.442584e+05   \n",
       "max    7.430000e+02  9.244552e+07   5.958504e+07    4.958504e+07   \n",
       "\n",
       "       oldbalanceDest  newbalanceDest       isFraud  isFlaggedFraud  \n",
       "count    6.362620e+06    6.362620e+06  6.362620e+06    6.362620e+06  \n",
       "mean     1.100702e+06    1.224996e+06  1.290820e-03    2.514687e-06  \n",
       "std      3.399180e+06    3.674129e+06  3.590480e-02    1.585775e-03  \n",
       "min      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n",
       "25%      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n",
       "50%      1.327057e+05    2.146614e+05  0.000000e+00    0.000000e+00  \n",
       "75%      9.430367e+05    1.111909e+06  0.000000e+00    0.000000e+00  \n",
       "max      3.560159e+08    3.561793e+08  1.000000e+00    1.000000e+00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>-0.010058</td>\n",
       "      <td>-0.010299</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>0.025888</td>\n",
       "      <td>0.031578</td>\n",
       "      <td>0.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>0.022373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.007861</td>\n",
       "      <td>0.294137</td>\n",
       "      <td>0.459304</td>\n",
       "      <td>0.076688</td>\n",
       "      <td>0.012295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <td>-0.010058</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>0.042029</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>0.003835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <td>-0.010299</td>\n",
       "      <td>-0.007861</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067812</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>-0.008148</td>\n",
       "      <td>0.003776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <td>0.027665</td>\n",
       "      <td>0.294137</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>0.067812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976569</td>\n",
       "      <td>-0.005885</td>\n",
       "      <td>-0.000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newbalanceDest</th>\n",
       "      <td>0.025888</td>\n",
       "      <td>0.459304</td>\n",
       "      <td>0.042029</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>0.976569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <td>0.031578</td>\n",
       "      <td>0.076688</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>-0.008148</td>\n",
       "      <td>-0.005885</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>0.044109</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    step    amount  oldbalanceOrg  newbalanceOrig  \\\n",
       "step            1.000000  0.022373      -0.010058       -0.010299   \n",
       "amount          0.022373  1.000000      -0.002762       -0.007861   \n",
       "oldbalanceOrg  -0.010058 -0.002762       1.000000        0.998803   \n",
       "newbalanceOrig -0.010299 -0.007861       0.998803        1.000000   \n",
       "oldbalanceDest  0.027665  0.294137       0.066243        0.067812   \n",
       "newbalanceDest  0.025888  0.459304       0.042029        0.041837   \n",
       "isFraud         0.031578  0.076688       0.010154       -0.008148   \n",
       "isFlaggedFraud  0.003277  0.012295       0.003835        0.003776   \n",
       "\n",
       "                oldbalanceDest  newbalanceDest   isFraud  isFlaggedFraud  \n",
       "step                  0.027665        0.025888  0.031578        0.003277  \n",
       "amount                0.294137        0.459304  0.076688        0.012295  \n",
       "oldbalanceOrg         0.066243        0.042029  0.010154        0.003835  \n",
       "newbalanceOrig        0.067812        0.041837 -0.008148        0.003776  \n",
       "oldbalanceDest        1.000000        0.976569 -0.005885       -0.000513  \n",
       "newbalanceDest        0.976569        1.000000  0.000535       -0.000529  \n",
       "isFraud              -0.005885        0.000535  1.000000        0.044109  \n",
       "isFlaggedFraud       -0.000513       -0.000529  0.044109        1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test_split(\n",
    "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, \n",
    "    random_state=None, shuffle=True):\n",
    "        \n",
    "    assert train_size + val_size + test_size == 1\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_size/(train_size+val_size), \n",
    "        random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'isFraud', axis = 1 \n",
    "           )\n",
    "y= df['isFraud']\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
    "    X, y, train_size=0.6, val_size=0.2, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True), \n",
    "    StandardScaler(), \n",
    "    LogisticRegression(solver='lbfgs')\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3817572,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7100638153319057"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1270908\n",
      "           1       0.92      0.42      0.58      1616\n",
      "\n",
      "   micro avg       1.00      1.00      1.00   1272524\n",
      "   macro avg       0.96      0.71      0.79   1272524\n",
      "weighted avg       1.00      1.00      1.00   1272524\n",
      "\n",
      "accuracy 0.9992180894034218\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))\n",
    "print('accuracy', accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 528, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 267, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1363, in fit\n    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 917, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 182, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 549, in __init__\n    self.results = batch()\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 755, in logistic_regression_path\n    iprint=iprint, pgtol=tol, maxiter=max_iter)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 199, in fmin_l_bfgs_b\n    **opts)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 335, in _minimize_lbfgsb\n    f, g = func_and_grad(x)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 285, in func_and_grad\n    f = fun(x, *args)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\", line 300, in function_wrapper\n    return function(*(wrapper_args + args))\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\", line 63, in __call__\n    fg = self.fun(x, *args)\n  File \"C:\\Users\\dakot\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 122, in _logistic_loss_and_grad\n    z0 = sample_weight * (z - 1) * y\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-872a35250e35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n\u001b[0;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my_pred_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DO NOT RUN LOCALLY WITHOUT 32G RAM INSTALLED!\n",
    "#param_grid = {\n",
    "#     'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "# grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_grid = grid.predict(X_test)\n",
    "\n",
    "# print(\"Baseline:\")\n",
    "# print()\n",
    "# print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "# print()\n",
    "# print(\"Best CV scores: {:.2f}\".format(grid.best_score_))\n",
    "# print()\n",
    "# print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99873\n",
       "1    0.00127\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "weights = ({0:1,1:10000000000})\n",
    "class_sep = 0.8\n",
    "\n",
    "X, y = make_classification(n_samples=n_samples, n_features=2, n_informative=2, \n",
    "                           n_redundant=0, n_repeated=0, n_classes=2, \n",
    "                           n_clusters_per_class=1, weights=weights, \n",
    "                           class_sep=class_sep, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1270908\n",
      "           1       0.92      0.42      0.58      1616\n",
      "\n",
      "   micro avg       1.00      1.00      1.00   1272524\n",
      "   macro avg       0.96      0.71      0.79   1272524\n",
      "weighted avg       1.00      1.00      1.00   1272524\n",
      "\n",
      "accuracy 0.9992180894034218\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))\n",
    "print('accuracy', accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def confusion_viz(y_true, y_pred):\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    return sns.heatmap(matrix, annot=True, \n",
    "                       fmt=',', linewidths=1, linecolor='grey', \n",
    "                       square=True, \n",
    "                       xticklabels=['Predicted\\nNO', 'Predicted\\nYES'], \n",
    "                       yticklabels=['Actual\\nNO', 'Actual\\nYES'])\n",
    "\n",
    "confusion_viz(y_val, y_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_242_Validate_classification_problems.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
